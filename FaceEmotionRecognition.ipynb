{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6eabd9f-07f9-4128-a904-495de2b28b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_preprocessing in c:\\users\\mithu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\mithu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras_preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mithu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras_preprocessing) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "!pip install keras_preprocessing\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5458c489-122e-4561-9967-5fac13e16298",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = r\"D:\\Face Emotion Recognition\\train\"\n",
    "TEST_DIR =  r\"D:\\Face Emotion Recognition\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2129f02-31f9-4901-8a3e-a2ef2dfd549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3845e0-09ee-4d31-8563-f658674c13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                                                   image     label\n",
      "0      D:\\Face Emotion Recognition\\train\\angry\\Traini...     angry\n",
      "1      D:\\Face Emotion Recognition\\train\\angry\\Traini...     angry\n",
      "2      D:\\Face Emotion Recognition\\train\\angry\\Traini...     angry\n",
      "3      D:\\Face Emotion Recognition\\train\\angry\\Traini...     angry\n",
      "4      D:\\Face Emotion Recognition\\train\\angry\\Traini...     angry\n",
      "...                                                  ...       ...\n",
      "28704  D:\\Face Emotion Recognition\\train\\surprise\\Tra...  surprise\n",
      "28705  D:\\Face Emotion Recognition\\train\\surprise\\Tra...  surprise\n",
      "28706  D:\\Face Emotion Recognition\\train\\surprise\\Tra...  surprise\n",
      "28707  D:\\Face Emotion Recognition\\train\\surprise\\Tra...  surprise\n",
      "28708  D:\\Face Emotion Recognition\\train\\surprise\\Tra...  surprise\n",
      "\n",
      "[28709 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbb2bc9-af94-40a2-8859-b372b678a450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                                                  image     label\n",
      "0     D:\\Face Emotion Recognition\\test\\angry\\Private...     angry\n",
      "1     D:\\Face Emotion Recognition\\test\\angry\\Private...     angry\n",
      "2     D:\\Face Emotion Recognition\\test\\angry\\Private...     angry\n",
      "3     D:\\Face Emotion Recognition\\test\\angry\\Private...     angry\n",
      "4     D:\\Face Emotion Recognition\\test\\angry\\Private...     angry\n",
      "...                                                 ...       ...\n",
      "7019  D:\\Face Emotion Recognition\\test\\surprise\\Publ...  surprise\n",
      "7020  D:\\Face Emotion Recognition\\test\\surprise\\Publ...  surprise\n",
      "7021  D:\\Face Emotion Recognition\\test\\surprise\\Publ...  surprise\n",
      "7022  D:\\Face Emotion Recognition\\test\\surprise\\Publ...  surprise\n",
      "7023  D:\\Face Emotion Recognition\\test\\surprise\\Publ...  surprise\n",
      "\n",
      "[7024 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1d962e-a2f5-4396-a687-60569f6c03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c829354-89fc-400b-9239-76c1829b8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115f2bfe-d335-42c9-b76e-6cc3e230b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4552e27df98a44f0b5d4e782d4aae863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mithu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b508a46b4a74db6a2a82bcb0efd5cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40914fb-5f0e-422c-96ce-7ec13ee438cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6148216a-3fea-4fbc-9cdd-3aff6d67676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c640be-a091-4772-9282-2a4501ec034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mithu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d63e4055-1d3f-4bc3-89d2-f675445060e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 27/225\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 677ms/step - accuracy: 0.2350 - loss: 1.8705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61ed04d-1c78-481a-9778-8e7db23c9587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3e53c4-56f3-49eb-aab6-6e686c11e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb13d689-7b34-4f3b-9090-c1579f45aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "def ef(image):\n",
    "    img = load_img(image, grayscale=True)\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d9fe3d-934c-468c-98c2-dffd940cf075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mithu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\ML Project\\\\train\\\\sad\\\\Training_120178.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mML Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msad\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTraining_120178.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal image is of sad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img)\n\u001b[0;32m      5\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m label[pred\u001b[38;5;241m.\u001b[39margmax()]\n",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m, in \u001b[0;36mef\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mef\u001b[39m(image):\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     feature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m      5\u001b[0m     feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:113\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# convert it to an 8-bit grayscale image.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\ML Project\\\\train\\\\sad\\\\Training_120178.jpg'"
     ]
    }
   ],
   "source": [
    "image = r\"D:\\ML Project\\train\\sad\\Training_120178.jpg\"\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed1c331-1dc8-4e6b-ac18-176312c5fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154fb730-149d-4000-8c0e-b58bfbe88831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28ef28f16c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = r\"D:\\Face Emotion Recognition\\train\\sad\\Training_120178.jpg\"\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)\n",
    "plt.imshow(img.reshape(48, 48), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75bf9d7c-7c14-4de6-baad-2061e1cb3ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of fear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28383fc59f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = r\"D:\\Face Emotion Reco\\train\\fear\\Training_536165.jpg\"\n",
    "print(\"original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683abf2f-0c9b-48c7-9c42-2956422b6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model architecture from JSON file\n",
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# Load the pre-trained model weights\n",
    "model.load_weights(\"facialemotionmodel.h5\")\n",
    "\n",
    "# Load the Haar cascade classifier for face detection\n",
    "haar_file = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "# Define a function to extract features from an image\n",
    "def extract_features(image):\n",
    "    feature = np.array(image)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "# Open the webcam (camera)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "# Define labels for emotion classes\n",
    "labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    i, im = webcam.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(im, 1.3, 5)\n",
    "\n",
    "    try:\n",
    "        # For each detected face, perform facial emotion recognition\n",
    "        for (p, q, r, s) in faces:\n",
    "            # Extract the region of interest (ROI) which contains the face\n",
    "            image = gray[q:q + s, p:p + r]\n",
    "\n",
    "            # Draw a rectangle around the detected face\n",
    "            cv2.rectangle(im, (p, q), (p + r, q + s), (255, 0, 0), 2)\n",
    "\n",
    "            # Resize the face image to the required input size (48x48)\n",
    "            image = cv2.resize(image, (48, 48))\n",
    "\n",
    "            # Extract features from the resized face image\n",
    "            img = extract_features(image)\n",
    "\n",
    "            # Make a prediction using the trained model\n",
    "            pred = model.predict(img)\n",
    "\n",
    "            # Get the predicted label for emotion\n",
    "            prediction_label = labels[pred.argmax()]\n",
    "\n",
    "            # Display the predicted emotion label near the detected face\n",
    "            cv2.putText(im, f'Emotion: {prediction_label}', (p - 10, q - 10),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 0, 255))\n",
    "\n",
    "        # Display the frame with annotations in real-time\n",
    "        cv2.imshow(\"Real-time Facial Emotion Recognition\", im)\n",
    "\n",
    "        # Break the loop if the 'Esc' key is pressed\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    except cv2.error:\n",
    "        pass\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718915d8-77c0-473b-807d-0f8f90b81ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
